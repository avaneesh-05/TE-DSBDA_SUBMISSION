{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Data Analytics III - Na\u00efve Bayes on Iris Dataset\n", "\n", "1. Implement Simple Na\u00efve Bayes classification algorithm using Python on the iris dataset.\n", "2. Compute Confusion matrix to find TP, FP, TN, FN, Accuracy, Error rate, Precision, Recall."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Import necessary libraries\n", "import seaborn as sns\n", "import pandas as pd\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.naive_bayes import GaussianNB\n", "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n", "import matplotlib.pyplot as plt\n", "import numpy as np"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load the Iris dataset\n", "iris = sns.load_dataset('iris')\n", "\n", "# Display first few rows\n", "iris.head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Separate features and target\n", "X = iris.drop('species', axis=1)\n", "y = iris['species']\n", "\n", "# Split into train and test sets\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Train Na\u00efve Bayes classifier\n", "model = GaussianNB()\n", "model.fit(X_train, y_train)\n", "\n", "# Make predictions\n", "y_pred = model.predict(X_test)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Confusion matrix\n", "conf_matrix = confusion_matrix(y_test, y_pred, labels=model.classes_)\n", "conf_matrix_df = pd.DataFrame(conf_matrix, index=model.classes_, columns=model.classes_)\n", "print(\"Confusion Matrix:\")\n", "print(conf_matrix_df)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Classification report\n", "print(\"\\nClassification Report:\")\n", "print(classification_report(y_test, y_pred, target_names=model.classes_))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Accuracy and Error Rate\n", "accuracy = accuracy_score(y_test, y_pred)\n", "error_rate = 1 - accuracy\n", "\n", "print(f\"Accuracy: {accuracy:.2f}\")\n", "print(f\"Error Rate: {error_rate:.2f}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Calculate TP, FP, FN, TN for each class\n", "labels = model.classes_\n", "conf_matrix = confusion_matrix(y_test, y_pred, labels=labels)\n", "print(\"Confusion Matrix:\\n\", pd.DataFrame(conf_matrix, index=labels, columns=labels))\n", "\n", "for i, label in enumerate(labels):\n", "    TP = conf_matrix[i, i]\n", "    FP = conf_matrix[:, i].sum() - TP\n", "    FN = conf_matrix[i, :].sum() - TP\n", "    TN = conf_matrix.sum() - (TP + FP + FN)\n", "    \n", "    print(f\"\\nClass: {label}\")\n", "    print(f\"TP: {TP}, FP: {FP}, FN: {FN}, TN: {TN}\")\n", "    \n", "    accuracy = (TP + TN) / (TP + FP + FN + TN)\n", "    error_rate = 1 - accuracy\n", "    precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n", "    recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n", "    \n", "    print(f\"Accuracy: {accuracy:.2f}\")\n", "    print(f\"Error Rate: {error_rate:.2f}\")\n", "    print(f\"Precision: {precision:.2f}\")\n", "    print(f\"Recall: {recall:.2f}\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.8"}}, "nbformat": 4, "nbformat_minor": 2}